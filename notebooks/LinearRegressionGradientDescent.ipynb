{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression via Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the data\n",
    "\n",
    "We use the multivariate simulated data from the regression lab, with the target variable being column 1 and the features being columns 2 and 3. We append a column of ones to the data matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"data/multivar_simulated/data.csv\", skip_header=1, delimiter=\",\")\n",
    "Y = data[:, 1]\n",
    "X = data[:, 2:]\n",
    "X = np.concatenate([X, np.ones(shape=(X.shape[0], 1))], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find our initial guess and the matrices needed for the gradient.  Choose a learning rate and a tolerance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "M0 = np.random.normal(0,1,size=(X.shape[1],1))\n",
    "A = ((X.T) @ Y).reshape(3,1)\n",
    "D = X.T @ X\n",
    "lr = .0001\n",
    "epsilon=.000001\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the gradient descent iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged after 2485 iterations\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    M = M0 - lr*(-2*A+2*(D@M0))\n",
    "    if np.allclose(M,M0,epsilon):\n",
    "        print(\"converged after {} iterations\".format(i))\n",
    "        break\n",
    "    M0=M.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.78815596]\n",
      " [-3.47876282]\n",
      " [ 6.0588864 ]]\n"
     ]
    }
   ],
   "source": [
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.78777492],\n",
       "       [-3.47899986],\n",
       "       [ 6.0608333 ]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(D) @ A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4de1eb631fc111013b2f441024ec0dcd7a567c3d6a338a26d91722f9a102f561"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
