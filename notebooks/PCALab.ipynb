{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Components Lab\n",
    "\n",
    "In this lab we will apply Principal Components Analysis to the Auto-MPG dataset that we studied in the Chapter on LinearRegression.  Before diving into the real data, we will work with the simulated data from the notes to show how to use python to and numpy to\n",
    "calculate the information we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "import seaborn as sns\n",
    "from bokeh.palettes import Spectral10, Category10\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated data for demo purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the datamatrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('simulated_pca_data.csv',delimiter=',')\n",
    "data.shape\n",
    "secret_label = data[:,-1]\n",
    "data=data[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consists of 200 samples, with 15 features per sample. It was constructed out of 4 different groups with different characteristics.  These groups are labeled but we will ignore the labels for the moment. To carry out principal component analysis,\n",
    "we must:\n",
    "\n",
    "1. center the data\n",
    "2. compute the covariance matrix D\n",
    "3. find the eigenvectors and eigenvalues of D\n",
    "\n",
    "Then we can:\n",
    "\n",
    "4. project the data into the space spanned by the first two eigenvectors of the covariance matrix and plot this\n",
    "5. draw the loading axes on the plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Centering the data\n",
    "\n",
    "To center the data, we subtract the mean of each column from that column.  The `mean` method computes the mean of each column of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(data,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_centered = data - np.mean(data,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtracting this from the data centers it -- python understands that when you subtract a scalar from a column, you are really subtracting that scalar from every entry in the column.\n",
    "\n",
    "Here we use a couple of programs we haven't discussed just to generate a gridplot for discussion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(pd.DataFrame(data_centered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Computing the Covariance Matrix\n",
    "\n",
    "Remember that the covariance matrix is $X_{0}^{\\intercal}X/N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.dot(data_centered.transpose(),data_centered)/200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Coefficients\n",
    "\n",
    "Remember that the correlation coefficient $R^2$ of two variables is\n",
    "$$\n",
    "R^{2}_{XY}=\\frac{\\sigma_{XY}^2}{\\sigma_{X}^2\\sigma_{Y}^2}\n",
    "$$\n",
    "\n",
    "We can extract this info from the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r(i,j):\n",
    "    return D[i,j]/np.sqrt(D[i,i]*D[j,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print(i, r(0,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.  Finding the eigenvalues and eigenvectors of D\n",
    "\n",
    "The command `np.linalg.eigh` returns a pair consisting of the vector of eigenvalues and the matrix of eigenvectors.\n",
    "By default, the eigenvalues are returned in increasing order, but we like them in decreasing order, so we reverse the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, P = np.linalg.eigh(D)\n",
    "L = L[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalue_plot = figure(title='Eigenvalues of Covariance Matrix')\n",
    "eigenvalue_plot.scatter(x=range(L.shape[0]),y=L,size=8)\n",
    "eigenvalue_plot.line(x=range(L.shape[0]),y=L,color='red')\n",
    "show(eigenvalue_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Projecting the data into the first two principal components\n",
    "\n",
    "The columns of the matrix `P` are the eigenvectors, but they are ordered like the eigenvalues (from smallest to largest).\n",
    "So the two most significant principal components are the *last two* columns of the matrix, and we need to reverse their order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC2 = np.dot(data_centered,P[:,-2::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scatter_plot = figure(title='Plot of First Two Principal Components',x_range=(-3,3),y_range=(-3,3))\n",
    "scatter_plot.scatter(x=PC2[:,0],y=PC2[:,1])\n",
    "show(scatter_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=['red','green','blue','orange','black']\n",
    "color_list = [colors[int(secret_label[i])] for i in range(200)]\n",
    "scatter_plot = figure(title='Plot of First Two Principal Components with secret labels',x_range=(-3,3),y_range=(-3,3))\n",
    "scatter_plot.scatter(x=PC2[:,0],y=PC2[:,1],color=color_list)\n",
    "show(scatter_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Draw the loading directions\n",
    "\n",
    "To project the axis of the $i^{th}$ feature into the space spanned by the two principal eigenvectors, we draw a line in the direction of the\n",
    "vector we obtain by multiplying the row vector $[0,\\ldots, 1,\\ldots 0]$, where the $1$ is in position $i$, into that space.  But multiplying\n",
    "that vector times the matrix $P$ just picks out the $i^{th}$ of of $P$, so we want to draw a line in the direction of the point corresponding to the $i^{th}$\n",
    "row of $P$.  For example, the $0^{th}$ feature is in the direction of $(PC[0,0],PC[0,1])$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(PC2.shape[1]):\n",
    "    scatter_plot.line(x=[-100*PC2[i,0],100*PC2[i,0]],y=[-100*PC2[i,1],100*PC2[i,1]],color='gray',line_dash='dashed')\n",
    "scatter_plot.title.text = 'Plot of First Two Principal Components with Feature Loadings'\n",
    "show(scatter_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for Auto Data\n",
    "\n",
    "Let's look at what PCA can tell us about the auto data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the data file, and drop the rows with ? for the horsepower\n",
    "data = np.genfromtxt('auto-mpg.csv',delimiter=',',skip_header=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the section on\n",
    "linear regression we explored the relationship between the gas mileage and various other properties of each \n",
    "car model.  We'll continue that analysis from the perspective of principal component analysis in this lab, focusing in particular on:\n",
    "\n",
    "- mileage (mpg) (column 0)\n",
    "- vehicle weight (column 4)\n",
    "- acceleration (column 5) -- note that big numbers mean poor acceleration!\n",
    "- horsepower  (column 3)\n",
    "- displacement (column 2)\n",
    "\n",
    "Display the data so you can see what it looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're only interested in mileage, weight, acceleration, and horsepower in this lab, let's just keep those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:,[0,2,3,4,5]]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:4,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This array has some missing data in it, indicated by nan's (Not a Number).  Here's how we find the\n",
    "bad spots.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(np.isnan(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This little function returns true if any element of a row of the matrix (axis=1) is nan. We look at it's first twenth entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(data).any(axis=1)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "argwhere looks for \"True\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(np.isnan(data).any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_rows = ~np.isnan(data).any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[good_rows,:]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go ahead and do PCA on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the steps:\n",
    "\n",
    "1. Center the data (and rescale it)\n",
    "2. Find the covariance matrix\n",
    "3. Compute its eigenvalues and eigenvectors and plot the eigenvalues\n",
    "4. Select the two largest eigenvalues and corresponding eigenvectors\n",
    "5. Draw a scatter plot of the data projected into the span of these two principal directions\n",
    "6. Draw the loadings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: center the data and rescale it\n",
    "data_centered = data - np.mean(data,axis=0)\n",
    "data_centered = data_centered/np.std(data,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(pd.DataFrame(data_centered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Find the covariance matrix.  Hint: data.shape[0] is the number of samples\n",
    "D = np.dot(data_centered.transpose(),data_centered)/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Find the eigenvalues and eigenvectors and plot them\n",
    "L, P = np.linalg.eigh(D)\n",
    "L = L[::-1]\n",
    "P = P[:,::-1]\n",
    "\n",
    "eigenvalue_plot = figure(title='Eigenvalues')\n",
    "eigenvalue_plot.circle(x=range(L.shape[0]),y=L)\n",
    "eigenvalue_plot.line(x=range(L.shape[0]),y=L,color='green')\n",
    "show(eigenvalue_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Project and plot the data\n",
    "PC2 = np.dot(data_centered, P[:,:2])\n",
    "scatter_plot = figure(title='Principal Components')\n",
    "\n",
    "scatter_plot.scatter(x=PC2[:,0],y=PC2[:,1])\n",
    "show(scatter_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: add the loading directions\n",
    "names = ['mpg','displacement','hp','weight','accel']\n",
    "for i in range(5):\n",
    "    scatter_plot.line(x=[0,P[i,0]],y=[0,P[i,1]],color=Category10[5][i],line_width=3,legend_label=names[i])\n",
    "scatter_plot.title.text = 'Principal Components with Loadings'\n",
    "show(scatter_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In looking at the figure above, notice that weight and mileage are almost perfect opposites -- so there is an unavoidable tradeoff with higher weight vehicles having lower mileage.  Moving to the lower right of the graph, you have better acceleration and also higher horsepower.  Horsepower and displacement point in roughly the same direction, though not perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So:\n",
    "\n",
    "- bottom left quadrant are bigger, relatively high mileage cars with poor acceleration\n",
    "- bottom right quadrant are bigger, high-horsepower, slow cars\n",
    "- upper right quadrant are bigger, faster, relatively high mileage cars \n",
    "- upper left quadrant are smaller, faster, relatively high mileage cars.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[]\n",
    "with open('auto-mpg.csv') as f:\n",
    "    for line in f:\n",
    "        fields = line.rstrip().split(',')\n",
    "        names.append(fields[-1])\n",
    "names = names[1:]\n",
    "names = [names[i] for i in range(len(names)) if good_rows[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source=ColumnDataSource({'pc0':PC2[:,0],'pc1':PC2[:,1],'type':names,'mpg':data[:,0],'disp':data[:,1],'hp':data[:,2],'wt':data[:,3],'accel':data[:,4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot=figure(title='PCA plot with labels (hover to see car type)')\n",
    "scatter_plot.scatter(x='pc0',y='pc1',source=source)\n",
    "scatter_plot.add_tools(HoverTool(tooltips=[(\"type\",\"@type\"),('mpg','@mpg'),('disp','@disp'),('hp','@hp'),('wt','@wt'),('accel','@accel')]))\n",
    "loadings = ['mpg','displacement','hp','weight','accel']\n",
    "for i in range(5):\n",
    "    scatter_plot.line(x=[0,P[i,0]],y=[0,P[i,1]],color=Category10[5][i],line_width=3,legend_label=loadings[i])\n",
    "show(scatter_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC = P.fit_transform(data_centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot=figure(title='sklearn version')\n",
    "scatter_plot.scatter(x=PC[:,0],y=PC[:,1])\n",
    "show(scatter_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loadings are in the components_ portion (each column is the projection of\n",
    "the corresponding feature into the space spanned by the PC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
