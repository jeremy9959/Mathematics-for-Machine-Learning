{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook,show\n",
    "import numpy as np\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-geneva",
   "metadata": {},
   "source": [
    "# Bayes Theorem Mini-Lab\n",
    "\n",
    "This lab is a chance to work with Bayes Theorem.  The underlying dataset is a collection of SMS (text) messages\n",
    "that were labelled as either 'junk' or 'real' as part of an attempt to build a classifier that could filter out\n",
    "junk text messages.\n",
    "\n",
    "The full dataset is in the 'complete.tsv' file -- this is a \"tab-separated\" file, rather than a \"comma-separated\"\n",
    "file.  But we won't be using this file directly.  Instead, we will just work with the simpler file 'data.csv'\n",
    "which is a comma separated file with two columns.  The first column is 0 or 1 depending on whether the corresponding\n",
    "text is real (0) or junk (1).  The second column is the length of the associated text message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('data.csv',delimiter=',',skip_header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-bowling",
   "metadata": {},
   "source": [
    "There are 5572 messages in the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-partnership",
   "metadata": {},
   "source": [
    "Let's separate out the junk and real messages to compare them.  One way to do that is to create\n",
    "an index array.  This command creates an array of True/False values based on whether that condition\n",
    "is true row-by-row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:,0]==0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-arnold",
   "metadata": {},
   "source": [
    "Notice that the first two entries in data are real and the third is junk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-wrapping",
   "metadata": {},
   "source": [
    "Now we use our index array to extract the real rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "real = data[data[:,0]==0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-fraction",
   "metadata": {},
   "source": [
    "There are 4825 real messages in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "real.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-sympathy",
   "metadata": {},
   "source": [
    "The average length of the real messages is computed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "real[:,1].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-equation",
   "metadata": {},
   "source": [
    "Now use a similar strategy to extract the junk rows and compute the mean length of the junk emails.\n",
    "What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "junk = data[data[:,0]==1,:]\n",
    "print(junk.shape)\n",
    "print('Mean Length of Junk Messages=',junk[:,1].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-appeal",
   "metadata": {},
   "source": [
    "One way to use this information about the lengths is to set a threshold value, of say 100 characters, and\n",
    "divide the messages into \"long\" and \"short\" messages using this threshold.  It seems that long messages\n",
    "are more likely to be junk.  We can use Bayes theorem to try to quantify this.\n",
    "\n",
    "Think of checking the length of a message like administering a test.  Getting a positive result -- finding a long\n",
    "message -- should increase the odds that our message is junk.  \n",
    "\n",
    "From the point of view of Bayes Theorem, we are interested in\n",
    "\n",
    "$$P(junk|long)$$\n",
    "\n",
    "which we can compute as\n",
    "\n",
    "$$\n",
    "P(junk|long) = \\frac{P(long|junk)P(junk)}{P(long)}\n",
    "$$\n",
    "\n",
    "And while we don't really know these probabilities, we can estimate them by looking at the frequency counts in our data.  (This approach is called \"Naive\" Bayes because we are naively assuming that the frequencies of data in our experiment are the real frequencies).\n",
    "\n",
    "To get started, we need a $2x2$ table of counts like this:\n",
    "\n",
    "|  | long  | short  | total |\n",
    "|---|---|---|---|\n",
    "| junk  |   |   |   |\n",
    "| real  |    |   |   |\n",
    "| total |     |   |  |\n",
    "\n",
    "from which we can compute the conditional probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-evanescence",
   "metadata": {},
   "source": [
    "These equations compute the number of elements in the (junk, long) and (junk, short) cells, with a threshold of 100 characters defining \"Long\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "junk_long = junk[junk[:,1]>=100].shape[0]\n",
    "junk_short=junk[junk[:,1]<100].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#real_long =\n",
    "#real_short ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-point",
   "metadata": {},
   "source": [
    "The conditional probability P(junk|long) is the percentage of long texts that are junk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(junk|long) = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-shape",
   "metadata": {},
   "source": [
    "The probability of being junk unconditionally is about 13%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "(junk_long+junk_short)/5572"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-requirement",
   "metadata": {},
   "source": [
    "This function computes the conditional probability as a function of a threshold, which can vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp(threshold):\n",
    "    junk_long = junk[junk[:,1]>=threshold].shape[0]\n",
    "    real_long = real[real[:,1]>=threshold].shape[0]\n",
    "    return junk_long/(junk_long+real_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-penetration",
   "metadata": {},
   "source": [
    "Setting the threshold to 130 makes P(junk|long) maximal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(200)\n",
    "y=np.array([cp(i) for i in x])\n",
    "f=figure()\n",
    "f.line(x=x,y=y)\n",
    "show(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-battery",
   "metadata": {},
   "source": [
    "Of course we are actually interested in detecting *real* messages.  About 85% of our messages our real, so if we just say everything is real, we are right 85% of the time.  Suppose we get a short message.  \n",
    "\n",
    "**What is the probability that it is real?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-royalty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
