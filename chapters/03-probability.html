<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Lectures on Machine Learning - 3&nbsp; Probability and Bayes Theorem</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/04-naive-bayes.html" rel="next">
<link href="../chapters/02-pca.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Probability and Bayes Theorem</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Lectures on Machine Learning</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/01-linear-regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Linear Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02-pca.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Principal Component Analysis</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/03-probability.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Probability and Bayes Theorem</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/04-naive-bayes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">The Naive Bayes classification method</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/05-logistic-regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Logistic Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/06-svm.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Support Vector Machines</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/20-references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="toc-section-number">3.1</span>  Introduction</a></li>
  <li><a href="#probability-basics" id="toc-probability-basics" class="nav-link" data-scroll-target="#probability-basics"><span class="toc-section-number">3.2</span>  Probability Basics</a>
  <ul class="collapse">
  <li><a href="#discrete-probability-examples" id="toc-discrete-probability-examples" class="nav-link" data-scroll-target="#discrete-probability-examples"><span class="toc-section-number">3.2.1</span>  Discrete probability examples</a></li>
  <li><a href="#continuous-probability-examples" id="toc-continuous-probability-examples" class="nav-link" data-scroll-target="#continuous-probability-examples"><span class="toc-section-number">3.2.2</span>  Continuous probability examples</a></li>
  </ul></li>
  <li><a href="#conditional-probability-and-bayes-theorem" id="toc-conditional-probability-and-bayes-theorem" class="nav-link" data-scroll-target="#conditional-probability-and-bayes-theorem"><span class="toc-section-number">3.3</span>  Conditional Probability and Bayes Theorem</a>
  <ul class="collapse">
  <li><a href="#bayes-theorem" id="toc-bayes-theorem" class="nav-link" data-scroll-target="#bayes-theorem"><span class="toc-section-number">3.3.1</span>  Bayes Theorem</a></li>
  <li><a href="#an-example" id="toc-an-example" class="nav-link" data-scroll-target="#an-example"><span class="toc-section-number">3.3.2</span>  An example</a></li>
  </ul></li>
  <li><a href="#independence" id="toc-independence" class="nav-link" data-scroll-target="#independence"><span class="toc-section-number">3.4</span>  Independence</a>
  <ul class="collapse">
  <li><a href="#examples" id="toc-examples" class="nav-link" data-scroll-target="#examples"><span class="toc-section-number">3.4.1</span>  Examples</a></li>
  </ul></li>
  <li><a href="#random-variables-mean-and-variance" id="toc-random-variables-mean-and-variance" class="nav-link" data-scroll-target="#random-variables-mean-and-variance"><span class="toc-section-number">3.5</span>  Random Variables, Mean, and Variance</a>
  <ul class="collapse">
  <li><a href="#independence-and-random-variables" id="toc-independence-and-random-variables" class="nav-link" data-scroll-target="#independence-and-random-variables"><span class="toc-section-number">3.5.1</span>  Independence and Random Variables</a></li>
  <li><a href="#expectation-mean-and-variance" id="toc-expectation-mean-and-variance" class="nav-link" data-scroll-target="#expectation-mean-and-variance"><span class="toc-section-number">3.5.2</span>  Expectation, Mean and Variance</a></li>
  </ul></li>
  <li><a href="#models-and-likelihood" id="toc-models-and-likelihood" class="nav-link" data-scroll-target="#models-and-likelihood"><span class="toc-section-number">3.6</span>  Models and Likelihood</a>
  <ul class="collapse">
  <li><a href="#sec-mlcoin" id="toc-sec-mlcoin" class="nav-link" data-scroll-target="#sec-mlcoin"><span class="toc-section-number">3.6.1</span>  Maximum Likelihood (Discrete Case)</a></li>
  <li><a href="#maximum-likelihood-continuous-case" id="toc-maximum-likelihood-continuous-case" class="nav-link" data-scroll-target="#maximum-likelihood-continuous-case"><span class="toc-section-number">3.6.2</span>  Maximum Likelihood (Continuous Case)</a></li>
  <li><a href="#sec-LRLike" id="toc-sec-LRLike" class="nav-link" data-scroll-target="#sec-LRLike"><span class="toc-section-number">3.6.3</span>  Linear Regression and likelihood</a></li>
  </ul></li>
  <li><a href="#bayesian-inference" id="toc-bayesian-inference" class="nav-link" data-scroll-target="#bayesian-inference"><span class="toc-section-number">3.7</span>  Bayesian Inference</a>
  <ul class="collapse">
  <li><a href="#bayesian-experiments-with-the-normal-distribution" id="toc-bayesian-experiments-with-the-normal-distribution" class="nav-link" data-scroll-target="#bayesian-experiments-with-the-normal-distribution"><span class="toc-section-number">3.7.1</span>  Bayesian experiments with the normal distribution</a></li>
  <li><a href="#bayesian-coin-flipping" id="toc-bayesian-coin-flipping" class="nav-link" data-scroll-target="#bayesian-coin-flipping"><span class="toc-section-number">3.7.2</span>  Bayesian coin flipping</a></li>
  <li><a href="#bayesian-regression-or-ridge-regression" id="toc-bayesian-regression-or-ridge-regression" class="nav-link" data-scroll-target="#bayesian-regression-or-ridge-regression"><span class="toc-section-number">3.7.3</span>  Bayesian Regression (or Ridge Regression)</a></li>
  </ul></li>
  <li><a href="#bibliography" id="toc-bibliography" class="nav-link" data-scroll-target="#bibliography">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Probability and Bayes Theorem</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="introduction" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">3.1</span> Introduction</h2>
<p>Probability theory is one of the three central mathematical tools in machine learning, along with multivariable calculus and linear algebra. Tools from probability allow us to manage the uncertainty inherent in data collected from real world experiments, and to measure the reliability of predictions that we might make from that data. In these notes, we will review some of the basic terminology of probability and introduce Bayesian inference as a technique in machine learning problems.</p>
<p>This will only be a superficial introduction to ideas from probability. For a thorough treatment, see <a href="https://probability.oer.math.uconn.edu/3160-oer">this open-source introduction to probability.</a> For a more applied emphasis, I recommend the excellent online course <a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/">Probabilistic Systems Analysis and Applied Probability</a> and its associated text <span class="citation" data-cites="Bertsekas">[<a href="20-references.html#ref-Bertsekas" role="doc-biblioref">1</a>]</span>.</p>
</section>
<section id="probability-basics" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="probability-basics"><span class="header-section-number">3.2</span> Probability Basics</h2>
<p>The theory of probability begins with a set <span class="math inline">\(X\)</span> of possible events or outcomes, together with a “probability” function <span class="math inline">\(P\)</span> on (certain) subsets of <span class="math inline">\(X\)</span> that measures “how likely” that combination of events is to occur.</p>
<p>The set <span class="math inline">\(X\)</span> can be discrete or continuous. For example, when flipping a coin, our set of possible events would be the discrete set <span class="math inline">\(\{H,T\}\)</span> corresponding to the possible events of flipping heads or tails. When measuring the temperature using a thermometer, our set of possible outcomes might be the set of real numbers, or perhaps an interval in <span class="math inline">\(\mathbb{R}\)</span>. The thermometer’s measurement is random because it is affected by, say, electronic noise, and so its reading is the true temperature perturbed by a random amount.</p>
<p>The values of <span class="math inline">\(P\)</span> are between <span class="math inline">\(0\)</span>, meaning that the event <em>will not</em> happen, and <span class="math inline">\(1\)</span>, meaning that it is certain to occur. As part of our set up, we assume that the total chance of some event from <span class="math inline">\(X\)</span> occurring is <span class="math inline">\(1\)</span>, so that <span class="math inline">\(P(X)=1\)</span>; and the chance of “nothing” happening is zero, so <span class="math inline">\(P(\emptyset)=0\)</span>. And if <span class="math inline">\(U\subset X\)</span> is some collection, then <span class="math inline">\(P(U)\)</span> is the chance of an event from <span class="math inline">\(U\)</span> occurring.</p>
<p>The last ingredient of this picture of probability is additivity. Namely, we assume that if <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> are subsets of <span class="math inline">\(X\)</span> that are disjoint, then <span class="math display">\[
P(U\cup V)=P(U)+P(V).
\]</span> Even more generally, we assume that this holds for (countably) infinite collections of disjoint subsets <span class="math inline">\(U_1,U_2,\ldots\)</span>, where <span class="math display">\[
P(U_1\cup U_2\cup\cdots)=\sum_{i=1}^{\infty} P(U_i)
\]</span></p>
<p><strong>Definition:</strong> The combination of a set <span class="math inline">\(X\)</span> of possible outcomes and a probability function <span class="math inline">\(P\)</span> on subsets of <span class="math inline">\(X\)</span> that satisfies <span class="math inline">\(P(X)=1\)</span>, <span class="math inline">\(0\le P(U)\le 1\)</span> for all <span class="math inline">\(U\)</span>, and is additive on countable disjoint collections of subsets of <span class="math inline">\(X\)</span> is called a (naive) probability space. <span class="math inline">\(X\)</span> is called the <em>sample space</em> and the subsets of <span class="math inline">\(X\)</span> are called <em>events</em>.</p>
<p><strong>Warning:</strong> The reason for the term “naive” in the above definition is that, if <span class="math inline">\(X\)</span> is an uncountable set such as the real numbers <span class="math inline">\(\mathbb{R}\)</span>, then the conditions in the definition are self-contradictory. This is a deep and rather surprising fact. To make a sensible definition of a probability space, one has to restrict the domain of the probability function <span class="math inline">\(P\)</span> to certain subsets of <span class="math inline">\(X\)</span>. These ideas form the basis of the mathematical subject known as measure theory. In these notes we will work with explicit probability functions and simple subsets such as intervals that avoid these technicalities.</p>
<section id="discrete-probability-examples" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="discrete-probability-examples"><span class="header-section-number">3.2.1</span> Discrete probability examples</h3>
<p>The simplest probability space arises in the analysis of coin-flipping. As mentioned earlier, the set <span class="math inline">\(X\)</span> contains two elements <span class="math inline">\(\{H,T\}\)</span>. The probability function <span class="math inline">\(P\)</span> is determined by its value <span class="math inline">\(P(\{H\})=p\)</span>, where <span class="math inline">\(0\le p\le 1\)</span>, which is the chance of the coin yielding a “head”. Since <span class="math inline">\(P(X)=1\)</span>, we have <span class="math inline">\(P(\{T\})=1-p\)</span>.</p>
<p>Other examples of discrete probability spaces arise from dice-rolling and playing cards. For example, suppose we roll two six-sided dice. There are <span class="math inline">\(36\)</span> possible outcomes from this experiment, each equally likely. If instead we consider the sum of the two values on the dice, our outcomes range from <span class="math inline">\(2\)</span> to <span class="math inline">\(12\)</span> and the probabilities of these outcomes are given by</p>
<table class="table">
<thead>
<tr class="header">
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
<th>11</th>
<th>12</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1/36</td>
<td>1/18</td>
<td>1/12</td>
<td>1/9</td>
<td>5/36</td>
<td>1/6</td>
<td>5/36</td>
<td>1/9</td>
<td>1/12</td>
<td>1/18</td>
<td>1/36</td>
</tr>
</tbody>
</table>
<p>A traditional deck of <span class="math inline">\(52\)</span> playing cards contains <span class="math inline">\(4\)</span> aces. Assuming that the chance of drawing any card is the same (and is therefore equal to <span class="math inline">\(1/52\)</span>), the probability of drawing an ace is <span class="math inline">\(4/52=1/13\)</span> since <span class="math display">\[
P(\{A_{\clubsuit},A_{\spadesuit},A_{\heartsuit},A_{\diamondsuit}\}) = 4P(\{A_{\clubsuit}\})=4/52=1/13
\]</span></p>
</section>
<section id="continuous-probability-examples" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="continuous-probability-examples"><span class="header-section-number">3.2.2</span> Continuous probability examples</h3>
<p>When the set <span class="math inline">\(X\)</span> is continuous, such as in the temperature measurement, we measure <span class="math inline">\(P(U)\)</span>, where <span class="math inline">\(U\subset X\)</span>, by giving a “probability density function” <span class="math inline">\(f:X\to \mathbb{R}\)</span> and declaring that <span class="math display">\[
P(U) = \int_{U}f(x) dX.
\]</span> Notice that our function <span class="math inline">\(f(x)\)</span> has to satisfy the condition <span class="math display">\[
P(X)=\int_{X} f(x)dX = 1.
\]</span></p>
<p>For example, in our temperature measurement example, suppose the “true” outside temperature is <span class="math inline">\(t_0\)</span>, and our thermometer gives a reading <span class="math inline">\(t\)</span>. Then a good model for the random error is to assume that the error <span class="math inline">\(x=t-t_0\)</span> is governed by the density function <span class="math display">\[
f_\sigma(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{-x^2/2\sigma^2}
\]</span> where <span class="math inline">\(\sigma\)</span> is a parameter. In a continuous situation such as this one, the probability of any particular outcome in <span class="math inline">\(X\)</span> is zero since <span class="math display">\[
P(\{t\})=\int_{t}^{t}f_{\sigma}(x)dx = 0
\]</span> Still, the shape of the density function does tell you where the values are concentrated – values where the density function is larger are more likely than those where it is smaller.</p>
<p>With this density function, and x=<span class="math inline">\(t-t_0\)</span>, the error in our measurement is given by <span id="eq-normal"><span class="math display">\[
P(|t-t_0|&lt;\delta)=\int_{-\delta}^{\delta} \frac{1}{\sigma\sqrt{2\pi}}e^{-x^2/2\sigma^2} dx
\tag{3.1}\]</span></span></p>
<p>The parameter <span class="math inline">\(\sigma\)</span> (called the <em>standard deviation</em>) controls how tightly the thermometer’s measurement is clustered around the true value <span class="math inline">\(t_0\)</span>; when <span class="math inline">\(\sigma\)</span> is large, the measurements are scattered widely, when small, they are clustered tightly. See <a href="#fig-density">Figure&nbsp;<span>3.1</span></a>.</p>
<div id="fig-density" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/density.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.1: Normal Density</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="conditional-probability-and-bayes-theorem" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="conditional-probability-and-bayes-theorem"><span class="header-section-number">3.3</span> Conditional Probability and Bayes Theorem</h2>
<p>The theory of conditional probability gives a way to study how partial information about an event informs us about the event as a whole. For example, suppose you draw a card at random from a deck. As we’ve seen earlier, the chance that card is an ace is <span class="math inline">\(1/13\)</span>. Now suppose that you learn that (somehow) that the card is definitely not a jack, king, or queen. Since there are 12 cards in the deck that are jacks, kings, or queens, the card you’ve drawn is one of the remaining 40 cards, which includes 4 aces. Thus the chance you are holding an ace is now <span class="math inline">\(4/40=1/10\)</span>.</p>
<p>In terms of notation, if <span class="math inline">\(A\)</span> is the event “my card is an ace” and <span class="math inline">\(B\)</span> is the event “my card is not a jack, queen, or king” then we say that <em>the probability of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span></em> is <span class="math inline">\(1/10\)</span>. The notation for this is <span class="math display">\[
P(A|B) = 1/10.
\]</span></p>
<p>More generally, if <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are events from a sample space <span class="math inline">\(X\)</span>, and <span class="math inline">\(P(B)&gt;0\)</span>, then <span class="math display">\[
P(A|B) = \frac{P(A\cap B)}{P(B)},
\]</span> so that <span class="math inline">\(P(A|B)\)</span> measures the chance that <span class="math inline">\(A\)</span> occurs among those situations in which <span class="math inline">\(B\)</span> occurs.</p>
<section id="bayes-theorem" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="bayes-theorem"><span class="header-section-number">3.3.1</span> Bayes Theorem</h3>
<p>Bayes theorem is a foundational result in probability.</p>
<p><strong>Theorem:</strong> Bayes Theorem says <span class="math display">\[
P(A|B) = \frac{P(B|A)P(A)}{P(B)}.
\]</span></p>
<p>If we use the definition of conditional probability given above, this is straightforward: <span class="math display">\[
\frac{P(B|A)P(A)}{P(B)} = \frac{P(B\cap A)}{P(B)} = P(A|B).
\]</span></p>
</section>
<section id="an-example" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="an-example"><span class="header-section-number">3.3.2</span> An example</h3>
<p>To illustrate conditional probability, let’s consider what happens when we administer the most reliable COVID-19 test, the PCR test, to an individual drawn from the population at large. There are two possible test results (positive and negative) and two possible true states of the person being tested (infected and not infected). Suppose I go to the doctor and get a COVID test which comes back positive. What is the probability that I actually have COVID?</p>
<p>Let’s let <span class="math inline">\(S\)</span> and <span class="math inline">\(W\)</span> stand for infected (sick) and not infected (well), and let <span class="math inline">\(+/-\)</span> stand for test positive or negative. Note that there are four possible outcomes of our experiment:</p>
<ul>
<li>test positive and infected (S+) – this is a <em>true positive</em>.</li>
<li>test positive and not infected (W+) – this is a <em>false positive</em>.</li>
<li>test negative and infected (S-) – this is a <em>false negative</em>.</li>
<li>test negative and not infected (W-) – this is a <em>true negative</em>.</li>
</ul>
<p>The <a href="https://www.icd10monitor.com/false-positives-in-pcr-tests-for-covid-19">CDC says</a> that the chance of a false positive – that is, the percentage of samples from well people that incorrectly yields a positive result – is about one-half of one percent, or 5 in 1000.</p>
<p>In other words, <span class="math display">\[
P(+|W) = P(W+)/P(W) = 5/1000=1/200
\]</span></p>
<p>On the other hand, the CDC tells us that chance of a false negative is 1 in 4, so <span class="math display">\[
P(-|S) = P(S-)/P(S) = .25.
\]</span> Since <span class="math inline">\(P(S-)+P(S+)=P(S).\)</span> since every test is either positive or negative, we have <span class="math display">\[
P(+|S) = .75.
\]</span></p>
<p>Suppose furthermore that the overall incidence of COVID-19 in the population is p.&nbsp;In other words, <span class="math inline">\(P(S)=p\)</span> so <span class="math inline">\(P(W)=1-p\)</span>. Then <span class="math display">\[P(S+)=P(S)P(+|S)=.75p\]</span> and <span class="math display">\[
P(W+)=P(W)P(+|W)=.005(1-p).
\]</span> Putting these together we get <span class="math inline">\(P(+)=.005+.745p\)</span></p>
<p>What I’m interested in is <span class="math inline">\(P(S|+)\)</span> – the chance that I’m sick, given that my test result was positive. By Bayes Theorem, <span class="math display">\[
P(S|+)=\frac{P(+|S)P(S)}{P(+)}=.75p/(.005+.745p)=\frac{750p}{5+745p}.
\]</span></p>
<p>As <a href="#fig-covidfn">Figure&nbsp;<span>3.2</span></a> shows, if the population incidence is low then a positive test is far from conclusive. Indeed, if the overall incidence of COVID is one percent, then a positive test result only implies a 60 percent chance that I am in fact infected.</p>
<p>Just to fill out the picture, we have <span class="math display">\[
P(-) = P(S-)+P(W-)=(P(S)-P(S+))+(P(W)-P(W+))
\]</span> which yields <span class="math display">\[
P(-)=1-.005+.005p-.75p = .995-.745p.
\]</span> Using Bayes Theorem, we obtain <span class="math display">\[
P(S|-) = \frac{P(-|S)P(S)}{P(-)} = .25p/(.995-.745p) =\frac{250p}{995-745p}.
\]</span> In this case, even though the false negative rate is pretty high (25 percent) overall, if the population incidence is one percent, then the probability that you’re sick given a negative result is only about <span class="math inline">\(.25\)</span> percent. So negative results are very likely correct!</p>
<div id="fig-covidfn" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/covidfn.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.2: P(S|+) vs P(S)</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="independence" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="independence"><span class="header-section-number">3.4</span> Independence</h2>
<p>Independence is one of the fundamental concepts in probability theory. Conceptually, two events are independent if the occurrence of one has does not influence the likelihood of the occurrence of the other. For example, successive flips of a coin are independent events, since the result of the second flip doesn’t have anything to do with the result of the first. On the other hand, whether or not it rains today and tomorrow are not independent events, since the weather tomorrow depends (in a complicated way) on the weather today.</p>
<p>We can formalize this idea of independence using the following definition.</p>
<p><strong>Definition:</strong> Let <span class="math inline">\(X\)</span> be a sample space and let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> be two events. Then <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <em>independent</em> if <span class="math inline">\(P(A\cap B)=P(A)P(B)\)</span>. Equivalently, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if <span class="math inline">\(P(A|B)=P(A)\)</span> and <span class="math inline">\(P(B|A)=P(B)\)</span>.</p>
<section id="examples" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="examples"><span class="header-section-number">3.4.1</span> Examples</h3>
<section id="coin-flipping" class="level4" data-number="3.4.1.1">
<h4 data-number="3.4.1.1" class="anchored" data-anchor-id="coin-flipping"><span class="header-section-number">3.4.1.1</span> Coin Flipping</h4>
<p>Suppose our coin has a probability of heads given by a real number <span class="math inline">\(p\)</span> between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>, and we flip our coin <span class="math inline">\(N\)</span> times. What is the chance of gettting <span class="math inline">\(k\)</span> heads, where <span class="math inline">\(0\le k\le N\)</span>? Any particular sequence of heads and tails containing <span class="math inline">\(k\)</span> heads and <span class="math inline">\(N-k\)</span> tails has probability <span class="math display">\[
P(\hbox{a particular sequence of $k$ heads among $N$ flips}) = p^{k}(1-p)^{N-k}.
\]</span> In addition, there are <span class="math inline">\(\binom{N}{k}\)</span> sequences of heads and tails containing <span class="math inline">\(k\)</span> heads. Thus the probability <span class="math inline">\(P(k,N)\)</span> of <span class="math inline">\(k\)</span> heads among <span class="math inline">\(N\)</span> flips is <span id="eq-binomial"><span class="math display">\[
P(k,N) = \binom{N}{k}p^{k}(1-p)^{N-k}.
\tag{3.2}\]</span></span></p>
<p>Notice that the binomial theorem gives us <span class="math inline">\(\sum_{k=0}^{N} P(k,N) =1\)</span> which is a reassuring check on our work.</p>
<p>The probability distribution on the set <span class="math inline">\(X=\{0,1,\ldots,N\}\)</span> given by <span class="math inline">\(P(k,N)\)</span> is called the <em>binomial distribution</em> with parameters <span class="math inline">\(N\)</span> and <span class="math inline">\(p\)</span>.</p>
</section>
<section id="a-simple-mixture" class="level4" data-number="3.4.1.2">
<h4 data-number="3.4.1.2" class="anchored" data-anchor-id="a-simple-mixture"><span class="header-section-number">3.4.1.2</span> A simple ‘mixture’</h4>
<p>Now let’s look at an example of events that are not independent. Suppose that we have two coins, with probabilities of heads <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_2\)</span> respectively; and assume these probabilities are different. We play the a game in which we first choose one of the two coins (with equal chance) and then flip it twice. Is the result of the second flip independent of the first? In other words, is <span class="math inline">\(P(HH)=P(H)^2\)</span>?</p>
<p>This type of situation is called a ‘mixture distribution’ because the probability of a head is a “mixture” of the probability coming from the two different coins.</p>
<p>The chance that the first flip is a head is <span class="math inline">\((p_1+p_2)/2\)</span> because it’s the chance of picking the first coin, and then getting a head, plus the chance of picking the second, and then getting a head. The chance of getting two heads in a row is <span class="math inline">\((p_1^2+p_2^2)/2\)</span> because it’s the chance, having picked the first coin, of getting two heads, plus the chance, having picked the second, of getting two heads.</p>
<p>Since <span class="math display">\[
\frac{p_1^2+p_2^2}{2}\not=\left(\frac{p_1+p_2}{2}\right)^2
\]</span> we see these events are not independent.</p>
<p>In terms of conditional probabilities, the chance that the second flip is a head, given that the first flip is, is computed as: <span class="math display">\[
P(HH|H) = \frac{p_1^2+p_2^2}{p_1+p_2}.
\]</span> From the Cauchy-Schwartz inequality one can show that <span class="math display">\[
\frac{p_1^2+p_2^2}{p_1+p_2}&gt;\frac{p_1+p_2}{2}.
\]</span></p>
<p>Why should this be? Why should the chance of getting a head on the second flip go up given that the first flip was a head? One way to think of this is that the first coin flip contains a little bit of information about which coin we chose. If, for example <span class="math inline">\(p_1&gt;p_2\)</span>, and our first flip is heads, then it’s just a bit more likely that we chose the first coin. As a result, the chance of getting another head is just a bit more likely than if we didn’t have that information. We can make this precise by considering the conditional probability <span class="math inline">\(P(p=p_1|H)\)</span> that we’ve chosen the first coin given that we flipped a head. From Bayes’ theorem:</p>
<p><span class="math display">\[
P(p=p_1|H) = \frac{P(H|p=p_1)P(p=p_1)}{P(H)}=\frac{p_1}{p_1+p_2}=\frac{1}{1+(p_2/p_1)}&gt;\frac{1}{2}
\]</span> since <span class="math inline">\((1+(p_2/p_1))&lt;2\)</span>.</p>
<p><strong>Exercise:</strong> Push this argument a bit further. Let <span class="math inline">\(p_1=\max(p_1,p_2)\)</span> Let <span class="math inline">\(P_N\)</span> be the conditional probability of getting heads assuming that the first <span class="math inline">\(N\)</span> flips were heads. Show that <span class="math inline">\(P_N\to p_1\)</span> as <span class="math inline">\(N\to\infty\)</span>. All those heads piling up make it more and more likely that you’re flipping the first coin and so the chance of getting heads approaches <span class="math inline">\(p_1\)</span>.</p>
</section>
<section id="an-example-with-a-continuous-distribution" class="level4" data-number="3.4.1.3">
<h4 data-number="3.4.1.3" class="anchored" data-anchor-id="an-example-with-a-continuous-distribution"><span class="header-section-number">3.4.1.3</span> An example with a continuous distribution</h4>
<p>Suppose that we return to our example of a thermometer which measures the ambient temperature with an error that is distributed according to the normal distribution, as in <a href="#eq-normal">Equation&nbsp;<span>3.1</span></a>. Suppose that we make 10 independent measurements <span class="math inline">\(t_1,\ldots, t_{10}\)</span> of the true temperature <span class="math inline">\(t_0\)</span>. What can we say about the distribution of these measurements?</p>
<p>In this case, independence means that <span class="math display">\[
P=P(|t_1-t_0|&lt;\delta,|t_2-t_0|&lt;\delta,\ldots) = P(|t_1-t_0|&lt;\delta)P(|t_2-t_0|&lt;\delta)\cdots P(|t_{10}-t_{0}|&lt;\delta)
\]</span> and therefore <span class="math display">\[
P = \left(\frac{1}{\sigma\sqrt{2\pi}}\right)^{10}\int_{-\delta}^{\delta}\cdots\int_{-\delta}^{\delta}
e^{-(\sum_{i=1}^{10} x_i^2)/2\sigma^2} dx_1\cdots dx_{10}
\]</span></p>
<p>One way to look at this is that the vector <span class="math inline">\(\mathbf{e}\)</span> of errors <span class="math inline">\((|t_1-t_0|,\ldots,|t_{10}-t_0|)\)</span> is distributed according to a <em>multivariate gaussian distribution</em>: <span id="eq-multivariategaussian"><span class="math display">\[
P(\mathbf{e}\in U) =\left(\frac{1}{\sigma\sqrt{2\pi}}\right)^{10}\int_{U}
e^{-\|x\|^2/2\sigma^2} d\mathbf{x}
\tag{3.3}\]</span></span></p>
<p>where <span class="math inline">\(U\)</span> is a region in <span class="math inline">\(\mathbf{R}^{10}\)</span>.</p>
<p>The multivariate gaussian can also describe situations where independence does not hold. For simplicity, let’s work in two dimensions and consider the probability density on <span class="math inline">\(\mathbf{R}^{2}\)</span> given by <span class="math display">\[
P(\mathbf{e}\in U) = A\int_{U} e^{-(x_1^2-x_1x_2+x_2^2)/2\sigma^2} d\mathbf{x}.
\]</span> where the constant <span class="math inline">\(A\)</span> is chosen so that <span class="math display">\[
A\int_{\mathbf{R}^{2}}e^{-(x_1^2-x_1x_2+x_2^2)/2\sigma^2}d\mathbf{x} = 1.
\]</span></p>
<p>This density function as a “bump” concentrated near the origin in <span class="math inline">\(\mathbf{R}^{2}\)</span>, and its level curves are a family of ellipses centered at the origin. See <a href="#fig-multivariate">Figure&nbsp;<span>3.3</span></a> for a plot of this function with <span class="math inline">\(\sigma=1\)</span>.</p>
<div id="fig-multivariate" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ellipse.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.3: Multivariate Gaussian</figcaption><p></p>
</figure>
</div>
<p>In this situation we can look at the conditional probability of the first variable given the second, and see that the two variables are not independent. Indeed, if we fix <span class="math inline">\(x_2\)</span>, then the distribution of <span class="math inline">\(x_1\)</span> depends on our choice of <span class="math inline">\(x_2\)</span>. We could see this by a calculation, or we can just look at the graph: if <span class="math inline">\(x_2=0\)</span>, then the most likely values of <span class="math inline">\(x_1\)</span> cluster near zero, while if <span class="math inline">\(x_2=1\)</span>, then the most likely values of <span class="math inline">\(x_1\)</span> cluster somewhere above zero.</p>
</section>
</section>
</section>
<section id="random-variables-mean-and-variance" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="random-variables-mean-and-variance"><span class="header-section-number">3.5</span> Random Variables, Mean, and Variance</h2>
<p>Typically, when we are studying a random process, we aren’t necessarily accessing the underlying events, but rather we are making measurements that provide us with some information about the underlying events. For example, suppose our sample space <span class="math inline">\(X\)</span> is the set of throws of a pair of dice, so <span class="math inline">\(X\)</span> contains the <span class="math inline">\(36\)</span> possible combinations that can arise from the throws. What we are actually interested is the sum of the values of the two dice – that’s our “measurement” of this system. This rather vague notion of a measurement of a random system is captured by the very general idea of a <em>random variable</em>.</p>
<p><strong>Definition:</strong> Let <span class="math inline">\(X\)</span> be a sample space with probability function <span class="math inline">\(P\)</span>. A <em>random variable</em> on <span class="math inline">\(X\)</span> is a function <span class="math inline">\(f:X\to \mathbb{R}\)</span>.</p>
<p>Given a random variable <span class="math inline">\(f\)</span>, we can use the probability measure to decide how likely <span class="math inline">\(f\)</span> is to take a particular value, or values in a particular set by the formula <span class="math display">\[
P(f(x)\in U) = P(f^{-1}(U))
\]</span></p>
<p>In the dice rolling example, the random variable <span class="math inline">\(S\)</span> that assigns their sum to the pair of values obtained on two dice is a random variable. Those values lie between <span class="math inline">\(2\)</span> and <span class="math inline">\(12\)</span> and we have <span class="math display">\[
P(S=k) = P(S^{-1}(\{k\}))=P(\{(x,y): x+y=k\})
\]</span> where <span class="math inline">\((x,y)\)</span> runs through <span class="math inline">\(\{1,2,\ldots,6\}^{2}\)</span> representing the two values and <span class="math inline">\(P((x,y))=1/36\)</span> since all throws are equally likely.</p>
<p>Let’s look at a few more examples, starting with what is probably the most fundamental of all.</p>
<p><strong>Definition:</strong> Let <span class="math inline">\(X\)</span> be a sample space with two elements, say <span class="math inline">\(H\)</span> and <span class="math inline">\(T\)</span>, and suppose that <span class="math inline">\(P(H)=p\)</span> for some <span class="math inline">\(0\le p\le 1\)</span>. Then the random variable that satisfies <span class="math inline">\(f(H)=1\)</span> and <span class="math inline">\(f(T)=0\)</span> is called a Bernoulli random variable with parameter <span class="math inline">\(p\)</span>.</p>
<p>In other words, a Bernoulli random variable gives the value <span class="math inline">\(1\)</span> when a coin flip is heads, and <span class="math inline">\(0\)</span> for tails.</p>
<p>Now let’s look at what we earlier called the binomial distribution.</p>
<p><strong>Definition:</strong> Let <span class="math inline">\(X\)</span> be a sample space consisting of strings of <span class="math inline">\(H\)</span> and <span class="math inline">\(T\)</span> of length <span class="math inline">\(N\)</span>, with the probability of a <em>particular string</em> <span class="math inline">\(S\)</span> with <span class="math inline">\(k\)</span> heads and <span class="math inline">\(N-k\)</span> tails given by <span class="math display">\[
P(S)=p^{k}(1-p)^{N-k}
\]</span> for some <span class="math inline">\(0\le p\le 1\)</span>. In other words, <span class="math inline">\(X\)</span> is the sample space consisting of <span class="math inline">\(N\)</span> independent flips of a coin with probability of heads given by <span class="math inline">\(p\)</span>.</p>
<p>Let <span class="math inline">\(f:X\to \mathbb{R}\)</span> be the function which counts the number of <span class="math inline">\(H\)</span> in the string. We can express <span class="math inline">\(f\)</span> in terms of Bernoulli random variables; indeed, <span class="math display">\[
f=X_1+\ldots+X_N
\]</span> where each <span class="math inline">\(X_i\)</span> is a Bernoulli random variable with parameter <span class="math inline">\(p\)</span>.</p>
<p>Now <span class="math display">\[
P(f=k) = \binom{N}{k}p^{k}(1-p)^{N-k}
\]</span> since <span class="math inline">\(f^{-1}(\{k\})\)</span> is the number of elements in the subset of strings of <span class="math inline">\(H\)</span> and <span class="math inline">\(T\)</span> of length <span class="math inline">\(N\)</span> containing exactly <span class="math inline">\(k\)</span> <span class="math inline">\(H\)</span>’s. This is our old friend the binomial distribution. So <em>a binomial distribution is the distribution of the sum of <span class="math inline">\(N\)</span> independent Bernoulli random variables.</em></p>
<p>For an example with a continuous random variable, suppose our sample space is <span class="math inline">\(\mathbf{R}^{2}\)</span> and the probability density is the simple multivariate normal <span class="math display">\[
P(\mathbf{x}\in U) = \left(\frac{1}{\sqrt{2\pi}}\right)^2\int_{U} e^{-\|\mathbf{x}\|^2/2} d\mathbf{x}.
\]</span> Let <span class="math inline">\(f\)</span> be the random variable <span class="math inline">\(f(\mathbf{x})=\|\mathbf{x}\|\)</span>. The function <span class="math inline">\(f\)</span> measures the Euclidean distance of a randomly drawn point from the origin. The set <span class="math display">\[U=f^{-1}([0,r))\subseteq\mathbf{R}^{2}\]</span> is the circle of radius <span class="math inline">\(r\)</span> in <span class="math inline">\(\mathbf{R}^{2}\)</span>. The probability that a randomly drawn point lies in this circle is <span class="math display">\[
P(f&lt;r) = \left(\frac{1}{\sqrt{2\pi}}\right)^2\int_{U} e^{-\|\mathbf{x}\|^2/2} d\mathbf{x}.
\]</span></p>
<p>We can actually evaluate this integral in closed form by using polar coordinates. We obtain <span class="math display">\[
P(f&lt;r) = \left(\frac{1}{\sqrt{2\pi}}\right)^2\int_{\theta=0}^{2\pi}\int_{\rho=0}^{r} e^{-\rho^2/2}\rho d\rho d\theta.
\]</span> Since <span class="math display">\[
\frac{d}{d\rho}e^{-\rho^2/2}=-\rho e^{-\rho^2/2}
\]</span> we have <span class="math display">\[\begin{align*}
P(f&lt;r)&amp;=-\frac{1}{2\pi}\theta e^{-\rho^2/2}|_{\theta=0}^{2\pi}|_{\rho=0}^{r}\cr
&amp;=1-e^{-r^2/2}\cr
\end{align*}\]</span></p>
<p>The probability density associated with this random variable is the derivative of <span class="math inline">\(1-e^{-r^2/2}\)</span> <span class="math display">\[
P(f\in [a,b])=\int_{r=a}^{b} re^{-r^2/2} dr
\]</span> as you can see by the fundamental theorem of calculus. This density is drawn in <a href="#fig-maxwell">Figure&nbsp;<span>3.4</span></a> where you can see that the points are clustered at a distance of <span class="math inline">\(1\)</span> from the origin.</p>
<div id="fig-maxwell" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/maxwell.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.4: Density of the Norm</figcaption><p></p>
</figure>
</div>
<section id="independence-and-random-variables" class="level3" data-number="3.5.1">
<h3 data-number="3.5.1" class="anchored" data-anchor-id="independence-and-random-variables"><span class="header-section-number">3.5.1</span> Independence and Random Variables</h3>
<p>We can extend the notion of independence from events to random variables.</p>
<p><strong>Definition:</strong> Let <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> be two random variables on a sample space <span class="math inline">\(X\)</span> with probability <span class="math inline">\(P\)</span>. Then <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> are independent if, for all intervals <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> in <span class="math inline">\(\mathbb{R}\)</span>, the events <span class="math inline">\(f^{-1}(U)\)</span> and <span class="math inline">\(g^{-1}(V)\)</span> are independent.</p>
<p>For discrete probability distributions, this means that, for all <span class="math inline">\(a,b\in\mathbb{R}\)</span>, <span class="math display">\[
P(f=a\hbox{\ and\ }g=b)=P(f=a)P(g=b).
\]</span></p>
<p>For continous probability distributions given by a density function <span class="math inline">\(P(x)\)</span>, independence can be more complicated to figure out.</p>
</section>
<section id="expectation-mean-and-variance" class="level3" data-number="3.5.2">
<h3 data-number="3.5.2" class="anchored" data-anchor-id="expectation-mean-and-variance"><span class="header-section-number">3.5.2</span> Expectation, Mean and Variance</h3>
<p>The most fundamental tool in the study of random variables is the concept of “expectation”, which is a fancy version of average. The word “mean” is a synonym for expectation – the mean of a random variable is the same as its expectation or “expected value.”</p>
<p><strong>Definition:</strong> Let <span class="math inline">\(X\)</span> be a sample space with probability measure <span class="math inline">\(P\)</span>. Let <span class="math inline">\(f:X\to \mathbb{R}\)</span> be a random variable. Then the <em>expectation</em> or <em>expected value</em> <span class="math inline">\(E[f]\)</span> of <span class="math inline">\(f\)</span> is <span class="math display">\[
E[f] = \int_X f(x)dP.
\]</span> More specifically, if <span class="math inline">\(X\)</span> is discrete, then <span class="math display">\[
E[f] = \sum_{x\in X} f(x)P(x)
\]</span> while if <span class="math inline">\(X\)</span> is continuous with probability density function <span class="math inline">\(p(x)dx\)</span> then <span class="math display">\[
E[f] = \int_{X} f(x)p(x)dx.
\]</span></p>
<p>If <span class="math inline">\(f\)</span> is a Bernoulli random variable with parameter <span class="math inline">\(p\)</span>, then <span class="math display">\[
E[f] = 1\cdot p+0\cdot (1-p) = p
\]</span></p>
<p>If <span class="math inline">\(f\)</span> is a binomial random variable with parameters <span class="math inline">\(p\)</span> and <span class="math inline">\(N\)</span>, then <span class="math display">\[
E[f] = \sum_{i=0}^{N} i\binom{N}{i}p^{i}(1-p)^{N-i}
\]</span> One can evaluate this using some combinatorial tricks, but it’s easier to apply this basic fact about expectations.</p>
<p><strong>Proposition:</strong> Expectation is linear: <span class="math inline">\(E[aX+bY]=aE[X]+bE[Y]\)</span> for random variables <span class="math inline">\(X,Y\)</span> and constants <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>.</p>
<p>The proof is an easy consequence of the expression of <span class="math inline">\(E\)</span> as a sum (or integral).</p>
<p>Since a binomial random variable <span class="math inline">\(Z\)</span> with parameters <span class="math inline">\(N\)</span> and <span class="math inline">\(p\)</span> is the sum of <span class="math inline">\(N\)</span> Bernoulli random variables, its expectation is <span class="math display">\[
E[X_1+\cdots+X_N]=Np.
\]</span></p>
<p>A more sophisticated property of expectation is that it is multiplicative when the random variables are independent.</p>
<p><strong>Proposition:</strong> Let <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> be two independent random variables. Then <span class="math inline">\(E[fg]=E[f]E[g]\)</span>.</p>
<p><strong>Proof:</strong> Let’s suppose that the sample space <span class="math inline">\(X\)</span> is discrete. By definition, <span class="math display">\[
E[f]=\sum_{x\in X}f(x)P(x)
\]</span> and we can rewrite this as <span class="math display">\[
E[f]=\sum_{a\in\mathbf{R}} aP(\{x: f(x)=a\}).
\]</span> Let <span class="math inline">\(Z\subset\mathbb{R}\)</span> be the range of <span class="math inline">\(f\)</span>. Then <span class="math display">\[\begin{align*}
E[fg]&amp;=\sum_{a\in Z} aP(\{x: fg(x)=a\}) \\
&amp;=\sum_{a\in Z}\sum_{(u,v)\in\genfrac{}{}{0pt}{}{\mathbf{Z}^{2}}{uv=a}}aP(\{x:f(x)=u\hbox{\ and\ }g(x)=v\}) \\
&amp;=\sum_{a\in Z}\sum_{\genfrac{}{}{0pt}{}{\mathbf{Z}^{2}}{uv=a}}uvP(\{x:f(x)=u\})P(\{x:g(x)=v\}) \\
&amp;=\sum_{u\in Z}uP(\{x:f(x)=u\})\sum_{v\in Z}vP(\{x:f(x)=v\}) \\
&amp;=E[f]E[g]
\end{align*}\]</span></p>
<section id="variance" class="level4" data-number="3.5.2.1">
<h4 data-number="3.5.2.1" class="anchored" data-anchor-id="variance"><span class="header-section-number">3.5.2.1</span> Variance</h4>
<p>The variance of a random variable is a measure of its dispersion around its mean.</p>
<p><strong>Definition:</strong> Let <span class="math inline">\(f\)</span> be a random variable. Then the variance is the expression <span class="math display">\[
\sigma^2(f) = E[(f-E[f])^2]=E[f^2]-(E[f])^2
\]</span> The square root of the variance is called the “standard deviation.”</p>
<p>The two formulae for the variance arise from the calculation <span class="math display">\[
E[(f-E[f])^2]=E[(f^2-2fE[f]+E[f]^2)]=E[f^2]-2E[f]^2+E[f]^2=E[f^2]-E[f]^2.
\]</span></p>
<p>To compute the variance of the Bernoulli random variable <span class="math inline">\(f\)</span> with parameter <span class="math inline">\(p\)</span>, we first compute <span class="math display">\[
E[f^2]=p(1)^2+(1-p)0^2=p.
\]</span> Since <span class="math inline">\(E[f]=p\)</span>, we have <span class="math display">\[
\sigma^2(f)=p-p^2=p(1-p).
\]</span></p>
<p>If <span class="math inline">\(f\)</span> is the binomial random variable with parameters <span class="math inline">\(N\)</span> and <span class="math inline">\(p\)</span>, we can again use the fact that <span class="math inline">\(f\)</span> is the sum of <span class="math inline">\(N\)</span> Bernoulli random variables <span class="math inline">\(X_1+\cdots+X_n\)</span> and compute</p>
<p><span class="math display">\[\begin{align*}
E[(\sum_{i}X_i)^2]-E[\sum_{i} X_{i}]^2 &amp;=E[\sum_{i} X_i^2+\sum_{i,j}X_{i}X_{j}]-N^2p^2\\
&amp;=Np+N(N-1)p^2-N^2p^2 \\
&amp;=Np(1-p)
\end{align*}\]</span></p>
<p>where we have used the fact that the square <span class="math inline">\(X^2\)</span> of a Bernoulli random variable is equal to <span class="math inline">\(X\)</span>.</p>
<p>For a continuous example, suppose that we consider a sample space <span class="math inline">\(\mathbb{R}\)</span> with the normal probability density <span class="math display">\[
P(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{-x^2/2\sigma^2}dx.
\]</span></p>
<p>The mean of the random variable <span class="math inline">\(x\)</span> is <span class="math display">\[
E[x] =\frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^{\infty} xe^{-x^2/2\sigma^2}dx=0
\]</span></p>
<p>since the function being integrated is odd. The variance is</p>
<p><span class="math display">\[
E[x^2] = \frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^{\infty} x^2e^{-x^2/2\sigma^2}dx.
\]</span></p>
<p>The trick to evaluating this integral is to consider the derivative:</p>
<p><span class="math display">\[
\frac{d}{d\sigma}\left[\frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-x^2/(2\sigma^2)}dx\right]=0
\]</span></p>
<p>where the result is zero since the quantity being differentiated is a constant (namely <span class="math inline">\(1\)</span>). Sorting through the resulting equation leads to the fact that</p>
<p><span class="math display">\[
E[x^2]=\sigma^2
\]</span></p>
<p>so that the <span class="math inline">\(\sigma^2\)</span> parameter in the normal distribution really <em>is</em> the variance of the associated random variable.</p>
</section>
</section>
</section>
<section id="models-and-likelihood" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="models-and-likelihood"><span class="header-section-number">3.6</span> Models and Likelihood</h2>
<p>A <em>statistical model</em> is a mathematical model that accounts for data via a process that incorporates random behavior in a structured way. We have seen several examples of such models in our discussion so far. For example, the Bernoulli process that describes the outcome of a series of coin flips as independent choices of heads or tails with probability <span class="math inline">\(p\)</span> is a simple statistical model; our more complicated mixture model in which we choose one of two coins at random and then flip that is a more complicated model.<br>
Our description of the variation in temperature measurements as arising from perturbations from the true temperature by a normally distributed amount is another example of a statistical model, this one involving a continuous random variable.</p>
<p>When we apply a mathematical model to understand data, we often have a variety of parameters in the model that we must adjust to get the model to best “fit” the observed data. For example, suppose that we observe the vibrations of a block attached to a spring. We know that the motion is governed by a second order linear differential equation, but the dynamics depend on the mass of the block, the spring constant, and the damping coefficient. By measuring the dynamics of the block over time, we can try to work backwards to figure out these parameters, after which we will be able to predict the block’s motion into the future.</p>
<section id="sec-mlcoin" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="sec-mlcoin"><span class="header-section-number">3.6.1</span> Maximum Likelihood (Discrete Case)</h3>
<p>To see this process in a statistical setting, let’s return to the simple example of a coin flip. The only parameter in our model is the probability <span class="math inline">\(p\)</span> of getting heads on a particular flip. Suppose that we flip the coin <span class="math inline">\(100\)</span> times and get <span class="math inline">\(55\)</span> heads and <span class="math inline">\(45\)</span> tails. What can we say about <span class="math inline">\(p\)</span>?</p>
<p>We will approach this question via the “likelihood” function for our data. We ask: for a particular value of the parameter <span class="math inline">\(p\)</span>, how likely is this outcome? From <a href="#eq-binomial">Equation&nbsp;<span>3.2</span></a> we have <span class="math display">\[
P(55H,45T)=\binom{100}{55}p^{55}(1-p)^{45}.
\]</span></p>
<p>This function is plotted in <a href="#fig-beta">Figure&nbsp;<span>3.5</span></a>. As you can see from that plot, it is extremely unlikely that we would have gotten <span class="math inline">\(55\)</span> heads if <span class="math inline">\(p\)</span> was smaller than <span class="math inline">\(.4\)</span> or greater than <span class="math inline">\(.7\)</span>, while the <em>most likely</em> value of <span class="math inline">\(p\)</span> occurs at the maximum value of this function, and a little calculus tells us that this point is where <span class="math inline">\(p=.55\)</span>. This <em>most likely</em> value of <span class="math inline">\(p\)</span> is called the <em>maximum likelihood estimate</em> for the parameter <span class="math inline">\(p\)</span>.</p>
<div id="fig-beta" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/beta.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.5: Likelihood Plot</figcaption><p></p>
</figure>
</div>
</section>
<section id="maximum-likelihood-continuous-case" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="maximum-likelihood-continuous-case"><span class="header-section-number">3.6.2</span> Maximum Likelihood (Continuous Case)</h3>
<p>Now let’s look at our temperature measurements where the error is normally distributed with variance parameter <span class="math inline">\(\sigma^2\)</span>. As we have seen earlier, the probability density of errors <span class="math inline">\(\mathbf{x}=(x_1,\ldots,x_n)\)</span> of <span class="math inline">\(n\)</span> independent measurements is <span class="math display">\[
P(\mathbf{x}) = \left(\frac{1}{\sigma\sqrt{2\pi}}\right)^{n}e^{-\|\mathbf{x}\|^2/(2\sigma^2)}d\mathbf{x}.
\]</span> (see <a href="#eq-multivariategaussian">Equation&nbsp;<span>3.3</span></a>). What should we use as the parameter <span class="math inline">\(\sigma\)</span>? We can ask which choice of <span class="math inline">\(\sigma\)</span> makes our data <em>most likely</em>. To calculate this, we think of the probability of a function of <span class="math inline">\(\sigma\)</span> and use Calculus to find the maximum. It’s easier to do this with the logarithm.</p>
<p><span class="math display">\[
\log P(\mathbf{x})=\frac{-\|\mathbf{x}\|^2}{2\sigma^2}-n\log{\sigma}+C
\]</span> where <span class="math inline">\(C\)</span> is a constant that we’ll ignore. Taking the derivative and setting it to zero, we obtain <span class="math display">\[
-\|\mathbf{x}\|^2\sigma^{-3}-n\sigma^{-1}=0
\]</span> which gives the formula <span class="math display">\[
\sigma^2=\frac{\|\mathbf{x}\|^2}{n}
\]</span></p>
<p>This should look familiar! The maximum likelihood estimate of the variance is the <em>mean-squared-error</em>.</p>
</section>
<section id="sec-LRLike" class="level3" data-number="3.6.3">
<h3 data-number="3.6.3" class="anchored" data-anchor-id="sec-LRLike"><span class="header-section-number">3.6.3</span> Linear Regression and likelihood</h3>
<p>In our earlier lectures we discussed linear regression at length. Our introduction of ideas from probability give us new insight into this fundamental tool. Consider a statistical model in which certain measured values <span class="math inline">\(y\)</span> depend linearly on <span class="math inline">\(x\)</span> up to a normally distributed error: <span class="math display">\[
y=mx+b+\epsilon
\]</span> where <span class="math inline">\(\epsilon\)</span> is drawn from the normal distribution with variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>The classic regression setting has us measuring a collection of <span class="math inline">\(N\)</span> points <span class="math inline">\((x_i,y_i)\)</span> and then asking for the “best” <span class="math inline">\(m\)</span>, <span class="math inline">\(b\)</span>, and <span class="math inline">\(\sigma^2\)</span> to explain these measurements. Using the likelihood perspective, each value <span class="math inline">\(y_i-mx_i-b\)</span> is an independent draw from the normal distribution with variance <span class="math inline">\(\sigma^2\)</span>, exactly like our temperature measurements in the one variable case.</p>
<p>The likelihood (density) of those draws is therefore <span class="math display">\[
P = \left(\frac{1}{\sigma\sqrt{2\pi}}\right)^Ne^{-\sum_{i}(y_i-mx_i-b)^2/(2\sigma^2)}.
\]</span> What is the maximum likelihood estimate of the parameters <span class="math inline">\(m\)</span>, <span class="math inline">\(b\)</span>, and <span class="math inline">\(\sigma^2\)</span>?</p>
<p>To find this we look at the logarithm of <span class="math inline">\(P\)</span> and take derivatives. <span class="math display">\[
\log(P) = -N\log(\sigma) -\frac{1}{2\sigma^2}\sum_{i}(y_i-mx_i-b)^2.
\]</span></p>
<p>As far as <span class="math inline">\(m\)</span> and <span class="math inline">\(b\)</span> are concerned, the minimum comes from the derivatives with respect to <span class="math inline">\(m\)</span> and <span class="math inline">\(b\)</span> of <span class="math display">\[
\sum_{i}(y_i-mx_i-b)^2.
\]</span> In other words, the maximum likelihood estimate <span class="math inline">\(m_*\)</span> and <span class="math inline">\(b_*\)</span> for <span class="math inline">\(m\)</span> and <span class="math inline">\(b\)</span> are <em>exactly the ordinary least squares estimates.</em></p>
<p>As far as <span class="math inline">\(\sigma^2\)</span> is concerned, we find just as above that the maximum likelihood estimate <span class="math inline">\(\sigma^2_*\)</span> is the mean squared error <span class="math display">\[
\sigma^2_*=\frac{1}{N}\sum_{i}(y_i-m_*x_i-b_*)^2.
\]</span></p>
<p>The multivariate case of regression proposes a model of the form <span class="math display">\[
Y=X\beta+\epsilon
\]</span> and a similar calculation again shows that the least squares estimates for <span class="math inline">\(\beta\)</span> are the maximum likelihood values for this model.</p>
</section>
</section>
<section id="bayesian-inference" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="bayesian-inference"><span class="header-section-number">3.7</span> Bayesian Inference</h2>
<p>We conclude our review of ideas from probability by examining the Bayesian perspective on data.</p>
<p>Suppose that we wish to conduct an experiment to determine the temperature outside our house. We begin our experiment with a statistical model that is supposed to explain the variability in the results. The model depends on some parameters that we wish to estimate. For example, the parameters of our experiment might be the ‘true’ temperature <span class="math inline">\(t_*\)</span> and the variance <span class="math inline">\(\sigma^2\)</span> of the error.</p>
<p>From the Bayesian point of view, at the beginning of this experiment we have an initial sense of what the temperature is likely to be, expressed in the form of a probability distribution. This initial information is called the <em>prior</em> distribution.</p>
<p>For example, if we know that it’s December in Connecticut, our prior distribution might say that the temperature is more likely to be between 20 and 40 degrees Fahrenheit and is quite unlikely to be higher than 60 or lower than 0. So our prior distribution might look like <a href="#fig-tempprior">Figure&nbsp;<span>3.6</span></a>.</p>
<div id="fig-tempprior" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/prior.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.6: Prior Distribution on Temperature</figcaption><p></p>
</figure>
</div>
<p>If we really have no opinion about the temperature other than its between say, <span class="math inline">\(-20\)</span> and <span class="math inline">\(100\)</span> degrees, our prior distribution might be uniform over that range, as in <a href="#fig-uniformprior">Figure&nbsp;<span>3.7</span></a>.</p>
<div id="fig-uniformprior" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/uniform.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.7: Uniform Prior</figcaption><p></p>
</figure>
</div>
<p>The choice of a prior will guide the interpretation of our experiments in ways that we will see shortly.</p>
<p>The next step in our experiment is the collection of data. Suppose we let <span class="math inline">\(\mathbf{t}=(t_1,t_2,\ldots, t_n)\)</span> be a random variable representing <span class="math inline">\(n\)</span> independent measurements of the temperature. We consider the <em>joint distribution</em> of the parameters <span class="math inline">\(t_*\)</span> and <span class="math inline">\(\sigma^2\)</span> and the possible measurements <span class="math inline">\(\mathbf{t}\)</span>: <span class="math display">\[
P(\mathbf{t},t_*,\sigma^2)=\left(\frac{1}{\sigma\sqrt{2\pi}}\right)^{n}e^{-\|\mathbf{t}-t_*\mathbf{e}\|^2/(2\sigma^2)}
\]</span> where <span class="math inline">\(\mathbf{e}=(1,1,\ldots, 1)\)</span>.</p>
<p>The conditional probability <span class="math inline">\(P(t_{*},\sigma^2|\mathbf{t})\)</span> is the distribution of the values of <span class="math inline">\(t_*\)</span> and <span class="math inline">\(\sigma^2\)</span><em>given</em>a value of the <span class="math inline">\(\mathbf{t}\)</span>. This is what we hope to learn by our experiment – namely, if we make a particular measurement, what does it tell us about <span class="math inline">\(t_*\)</span> and <span class="math inline">\(\sigma^2\)</span>?</p>
<p>Now suppose that we actually make some measurements, and so we obtain a specific set of values <span class="math inline">\(\mathbf{t}_0\)</span> for <span class="math inline">\(\mathbf{t}\)</span>.</p>
<p>By Bayes Theorem, <span class="math display">\[
P(t_{*},\sigma^2|\mathbf{t}=\mathbf{t}_0) = \frac{P(\mathbf{t}=\mathbf{t}_0|t_{*},\sigma^2)P(t_{*},\sigma^2)}{P(\mathbf{t}=\mathbf{t}_0)}
\]</span> We interpret this as follows:</p>
<ul>
<li>the left hand side <span class="math inline">\(P(t_{*},\sigma^2|\mathbf{t}=\mathbf{t}_0)\)</span> is called the <em>posterior distribution</em> and is the distribution of <span class="math inline">\(t_{*}\)</span> and <span class="math inline">\(\sigma^2\)</span> obtained by <em>updating our prior knowledge with the results of our experiment.</em></li>
<li>The probability <span class="math inline">\(P(\mathbf{t}=\mathbf{t}_{0}|t_{*},\sigma^2)\)</span> is the probability of obtaining the measurements we found for a particular value of the parameters <span class="math inline">\(t_{*}\)</span> and <span class="math inline">\(\sigma^2\)</span>.</li>
<li>The probability <span class="math inline">\(P(t_{*},\sigma^2)\)</span> is the <em>prior distribution</em> on the parameters that reflects our initial impression of the distribution of these parameters.</li>
<li>The denominator <span class="math inline">\(P(\mathbf{t}=\mathbf{t}_{0})\)</span> is the total probability of the results that we obtained, and is the integral over the distribution of the parameters weighted by their prior probability: <span class="math display">\[
P(\mathbf{t}=\mathbf{t}_{0})=\int_{t_{*},\sigma^2}P(\mathbf{t}=\mathbf{t}_{0}|t_{*},\sigma^2)P(t_{*},\sigma^2)
\]</span></li>
</ul>
<section id="bayesian-experiments-with-the-normal-distribution" class="level3" data-number="3.7.1">
<h3 data-number="3.7.1" class="anchored" data-anchor-id="bayesian-experiments-with-the-normal-distribution"><span class="header-section-number">3.7.1</span> Bayesian experiments with the normal distribution</h3>
<p>To illustrate these Bayesian ideas, we’ll consider the problem of measuring the temperature, but for simplicity let’s assume that we fix the variance in our error measurements at <span class="math inline">\(1\)</span> degree. Let’s use the prior distribution on the true temperature that I proposed in <a href="#fig-tempprior">Figure&nbsp;<span>3.6</span></a>, which is a normal distribution with variance <span class="math inline">\(15\)</span> “shifted” to be centered at <span class="math inline">\(30\)</span>: <span class="math display">\[
P(t_*)=\left(\frac{1}{\sqrt{2\pi}}\right)e^{-(t_*-30)^2/30}.
\]</span> The expected value <span class="math inline">\(E[t]\)</span> – the mean of the this distribution – is <span class="math inline">\(30\)</span>.</p>
<p>Since the error in our measurements is normally distributed with variance <span class="math inline">\(1\)</span>, we have <span class="math display">\[
P(t-t_{*})=\left(\frac{1}{\sqrt{2\pi}}\right)e^{-(t-t_{*})^2/2}
\]</span> or as a function of the absolute temperature, we have <span class="math display">\[
P(t,t_{*}) = \left(\frac{1}{\sqrt{2\pi}}\right)e^{-(t-t_*)^2/2}.
\]</span></p>
<p>Now we make a bunch of measurements to obtain <span class="math inline">\(\mathbf{t}_0=(t_1,\ldots, t_n)\)</span>. We have <span class="math display">\[
P(\mathbf{t}=\mathbf{t}_0|t_{*}) = \left(\frac{1}{\sqrt{2\pi}}\right)^ne^{-\|\mathbf{t}-t_*\mathbf{e}\|^2/2}.
\]</span></p>
<p>The total probability <span class="math inline">\(T=P(\mathbf{t}=\mathbf{t_0})\)</span> is hard to calculate, so let’s table that for a while. The posterior probability is <span class="math display">\[
P(t_{*}|\mathbf{t}=\mathbf{t}_{0}) = \frac{1}{T}
\left(\frac{1}{\sqrt{2\pi}}\right)^ne^{-\|\mathbf{t}-t_*\mathbf{e}\|^2/2}
\left(\frac{1}{\sqrt{2\pi}}\right)e^{-(t_*-30)^2/30}.
\]</span></p>
<p>Leaving aside the multiplicative constants for the moment, consider the exponential <span class="math display">\[
e^{-(\|\mathbf{t}-t_{*}\mathbf{e}\|^2/2+(t_{*}-30)^2)/30}.
\]</span> Since <span class="math inline">\(\mathbf{t}\)</span> is a vector of constants – it is a vector of our particular measurements – the exponent <span class="math display">\[
\|\mathbf{t}-t_{*}\mathbf{e}\|^2/2+(t_{*}-30)^2/30 = (t_{*}-30)^2/30+\sum_{i} (t_{i}-t_{*})^2/2
\]</span> is a quadratic polynomial in <span class="math inline">\(t_{*}\)</span> that simplifies: <span class="math display">\[
(t_{*}-30)^2/30+\sum_{i} (t_{i}-t_{*})^2/2 = At_{*}^2+Bt_{*}+C.
\]</span> Here <span class="math display">\[
A=(\frac{1}{30}+\frac{n}{2}),
\]</span> <span class="math display">\[
B=-2-\sum_{i} t_{i}
\]</span> <span class="math display">\[
C=30+\frac{1}{2}\sum_{i} t_{i}^2.
\]</span></p>
<p>We can complete the square to write <span class="math display">\[
At_{*}^2+Bt_{*}+C = (t_{*}-U)^2/2V +K
\]</span> where <span class="math display">\[
U=\frac{2+\sum_{i}t_{i}}{\frac{1}{15}+n}
\]</span> and <span class="math display">\[
V=\frac{1}{\frac{1}{15}+n}.
\]</span> So up to constants that don’t involve <span class="math inline">\(t_{*}\)</span>, the posterior density is of the form <span class="math display">\[
e^{(t_{*}-U)^2/2V}
\]</span> and since it is a probability density, the constants must work out to give total integral of <span class="math inline">\(1\)</span>. Therefore the posterior density is a normal distribution centered at <span class="math inline">\(U\)</span> and with variance <span class="math inline">\(V\)</span>. Here <span class="math inline">\(U\)</span> is called the<em>posterior mean</em>and <span class="math inline">\(V\)</span> the<em>posterior variance</em>.</p>
<p>To make this explicit, suppose <span class="math inline">\(n=5\)</span> and we measured the following temperatures: <span class="math display">\[
40, 41,39, 37, 44
\]</span> The mean of these observations is <span class="math inline">\(40.2\)</span> and the variance is <span class="math inline">\(5.4\)</span>.</p>
<p>A calculation shows that the posterior mean is <span class="math inline">\(40.1\)</span> and the posterior variance is <span class="math inline">\(0.2\)</span>. Comparing the prior with the posterior, we obtain the plot in <a href="#fig-comparison">Figure&nbsp;<span>3.8</span></a>. The posterior has a sharp peak at <span class="math inline">\(40.1\)</span> degrees. This value is just a bit smaller than the mean of the observed temperatures which is <span class="math inline">\(40.2\)</span> degrees. This difference is caused by the prior – our prior distribution said the temperature was likely to be around <span class="math inline">\(30\)</span> degrees, and so the prior pulls the observed mean a bit towards the prior mean taking into account past experience. Because the variance of the prior is large, it has a relatively small influence on the posterior.</p>
<p>The general version of the calculation above is summarized in this proposition.</p>
<p><strong>Proposition:</strong> Suppose that our statistical model for an experiment proposes that the measurements are normally distributed around an (unknown) mean value of <span class="math inline">\(\mu\)</span> with a (fixed) variance <span class="math inline">\(\sigma^2\)</span>. Suppose further that our prior distribution on the unknown mean <span class="math inline">\(\mu\)</span> is normal with mean <span class="math inline">\(\mu_0\)</span> and variance <span class="math inline">\(\tau^2\)</span>. Suppose we make measurements <span class="math display">\[
y_1,\ldots, y_n
\]</span> with mean <span class="math inline">\(\overline{y}\)</span>. Then the posterior distribution of <span class="math inline">\(\mu\)</span> is again normal, with posterior variance <span class="math display">\[
\tau'^2 = \frac{1}{\frac{1}{\tau^2}+\frac{n}{\sigma^2}}
\]</span> and posterior mean <span class="math display">\[
\mu' = \frac{\frac{\mu_0}{\tau^2}+\frac{n}{\sigma^2}\overline{y}}{\frac{1}{\frac{1}{\tau^2}+\frac{n}{\sigma^2}}}
\]</span></p>
<p>So the posterior mean is a sort of weighted average of the sample mean and the prior mean; and as <span class="math inline">\(n\to\infty\)</span>, the posterior mean approaches the sample mean – in other words, as you get more data, the prior has less and less influence on the results of the experiment.</p>
<div id="fig-comparison" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/priorposterior.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.8: Prior and Posterior</figcaption><p></p>
</figure>
</div>
</section>
<section id="bayesian-coin-flipping" class="level3" data-number="3.7.2">
<h3 data-number="3.7.2" class="anchored" data-anchor-id="bayesian-coin-flipping"><span class="header-section-number">3.7.2</span> Bayesian coin flipping</h3>
<p>For our final example in this fast overview of ideas from probability, we consider the problem of deciding whether a coin is fair. Our experiment consists of <span class="math inline">\(N\)</span> flips of a coin with unknown probability <span class="math inline">\(p\)</span> of heads, so the data consists of the number <span class="math inline">\(h\)</span> of heads out of the <span class="math inline">\(N\)</span> flips. To apply Bayesian reasoning, we need a prior distribution on <span class="math inline">\(p\)</span>. Let’s first assume that we have no reason to prefer one value of <span class="math inline">\(p\)</span> over another, and so we choose for our prior the uniform distribution on <span class="math inline">\(p\)</span> between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>.</p>
<p>We wish to analyze <span class="math inline">\(P(p|h)\)</span>, the probability distribution of <span class="math inline">\(p\)</span> given <span class="math inline">\(h\)</span> heads out of <span class="math inline">\(N\)</span> flips. Bayes Theorem gives us: <span class="math display">\[
P(p|h) = \frac{P(h|p)P(p)}{P(h)}
\]</span> where <span class="math display">\[
P(h|p) = \binom{N}{h}p^{h}(1-p)^{N-h}
\]</span> and <span class="math display">\[
P(h)=\int_{p=0}^{1} P(h|p)P(p) dp = \binom{N}{h}\int_{p=0}^{1} p^{h}(1-p)^{N-h}dp
\]</span> is a constant which insures that <span class="math display">\[\int_{p}P(p|h)dp=1.\]</span></p>
<p>We see that the posterior distribution <span class="math inline">\(P(p|h)\)</span> is proportional to the polynomial function <span class="math display">\[
P(p|h)\propto p^{h}(1-p)^{N-h}.
\]</span> As in <a href="#sec-mlcoin"><span>Section&nbsp;3.6.1</span></a>, we see that this function peaks at <span class="math inline">\(h/N\)</span>. This is called the maximum <em>a posteriori estimate</em> for <span class="math inline">\(p\)</span>.</p>
<p>Another way to summarize the posterior distribution <span class="math inline">\(P(p|h)\)</span> is to look at the expected value of <span class="math inline">\(p\)</span>. This is called the <em>posterior mean</em> of <span class="math inline">\(p\)</span>. To compute it, we need to know the normalization constant in the expression for <span class="math inline">\(P(p|h)\)</span>, and for that we can take advantage of the properties of a special function <span class="math inline">\(B(a,b)\)</span> called the Beta-function: <span class="math display">\[
B(a,b) = \int_{p=0}^{1} p^{a-1}(1-p)^{b-1} dp.
\]</span></p>
<p><strong>Proposition:</strong> If <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are integers, then <span class="math inline">\(B(a,b)=\frac{a+b}{ab}\frac{1}{\binom{a+b}{a}}\)</span>.</p>
<p><strong>Proof:</strong> Using integration by parts, one can show that <span class="math display">\[
B(a,b)=\frac{a-1}{b}B(a-1,b+1)
\]</span> and a simple calculation shows that <span class="math display">\[
B(1,b) = \frac{1}{b}.
\]</span> Let <span class="math display">\[
H(a,b)=\frac{a+b}{ab}\frac{1}{\binom{a+b}{a}} = \frac{(a-1)!(b-1)!}{(a+b-1)!}
\]</span> Then it’s easy to check that <span class="math inline">\(H\)</span> satsifies the same recurrences as <span class="math inline">\(B(a,b)\)</span>, and that <span class="math inline">\(H(1,b)=1/b\)</span>. So the two functions agree by induction.</p>
<p>Using this Proposition, we see that <span class="math display">\[
P(p|h) = \frac{p^{h}(1-p)^{N-h}}{B(h+1,N-h+1)}
\]</span> and <span class="math display">\[
E[p] = \frac{\int_{p=0}^{1} p^{h+1}(1-p)^{N-h}dp}{B(h+1,N-h+1)}=\frac{B(h+2,N-h+1)}{B(h+1,N-h+1)}.
\]</span> Sorting through this using the formula for <span class="math inline">\(B(a,b)\)</span> we obtain <span class="math display">\[
E[p]=\frac{h+1}{N+2}.
\]</span></p>
<p>So if we obtained <span class="math inline">\(55\)</span> heads out of <span class="math inline">\(100\)</span> flips, the maximum a posteriori estimate for <span class="math inline">\(p\)</span> is <span class="math inline">\(.55\)</span>, while the posterior mean is <span class="math inline">\(56/102=.549\)</span> – just a bit less.</p>
<p>Now suppose that we had some reason to believe that our coin was fair. Then we can choose a prior probability distribution that expresses this. For example, we can choose <span class="math display">\[
P(p) = \frac{1}{B(5,5)}p^{4}(1-p)^{4}.
\]</span> Here we use the Beta function to guarantee that <span class="math inline">\(\int_{0}^{1}P(p)dp=1\)</span>. We show this prior distribution in <a href="#fig-betaprior">Figure&nbsp;<span>3.9</span></a>.</p>
<div id="fig-betaprior" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/betaprior.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.9: Beta(5,5) Prior</figcaption><p></p>
</figure>
</div>
<p>If we redo our Bayes theorem calculation, we find that our posterior distribution is <span class="math display">\[
P(p|h) \propto p^{h+4}(1-p)^{N-h+4}
\]</span> and relying again on the Beta function for normalization we have <span class="math display">\[
P(p|h) = \frac{1}{B(h+5,N-h+5)}p^{h+4}(1-p)^{N-h+4}
\]</span> Here the maximum a posterior estimate for <span class="math inline">\(p\)</span> is <span class="math inline">\(h+4/N+8\)</span> while our posterior mean is <span class="math display">\[
\frac{B(h+6,N-h+5)}{B(h+5,N-h+5)} = \frac{h+5}{N+10}.
\]</span></p>
<p>In the situation of <span class="math inline">\(55\)</span> heads out of <span class="math inline">\(100\)</span>, the maximum a posteriori estimate is <span class="math inline">\(.546\)</span> and the posterior mean is <span class="math inline">\(.545\)</span>. These numbers have been pulled just a bit towards <span class="math inline">\(.5\)</span> because our prior knowledge makes us a little bit biased towards <span class="math inline">\(p=.5\)</span>.</p>
</section>
<section id="bayesian-regression-or-ridge-regression" class="level3" data-number="3.7.3">
<h3 data-number="3.7.3" class="anchored" data-anchor-id="bayesian-regression-or-ridge-regression"><span class="header-section-number">3.7.3</span> Bayesian Regression (or Ridge Regression)</h3>
<p>In this chapter we return to our discussion of linear regression and introduce some Bayesian ideas. The combination will lead us to the notion of “ridge” regression, which is a type of linear regression that includes a prior distribution on the coefficients that indicates our preference for smaller rather than larger coefficients. Introduction of this prior leads to a form of linear regression that is more resilient in situations where the independent variables are less independent than we would hope.</p>
<p>Before introducing these Bayesian ideas, let us recall from <a href="#sec-LRLike"><span>Section&nbsp;3.6.3</span></a> that ordinary least squares yields the parameters that give the “most likely” set of parameters for a model of the form <span class="math display">\[
Y=XM + \epsilon
\]</span> where the error <span class="math inline">\(\epsilon\)</span> is normally distributed with mean <span class="math inline">\(0\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, and the mean squared error becomes the maximum likelihood estimate of the variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>To put this into a Bayesian perspective, we notice that the linear regression model views <span class="math inline">\(Y-XM\)</span> as normally distributed given <span class="math inline">\(M\)</span>. That is, we see the probability <span class="math inline">\(P(Y-XM|M)\)</span> as normal with variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Then we introduce a prior distribution on the coefficients <span class="math inline">\(M\)</span>, assuming that they, too, are normally distributed around zero with variance <span class="math inline">\(\tau^2\)</span>. This means that <em>ab initio</em> we think that the coefficients are likely to be small.</p>
<p>From Bayes Theorem, we then have <span class="math display">\[
P(M|Y,X) = \frac{P(Y,X|M)P(M)}{P(Y,X)}
\]</span> and in distribution terms we have <span class="math display">\[
P(M|Y,X) = Ae^{\|Y-XM\|^2/\sigma^2}e^{-\|M\|^2/\tau^{2}}
\]</span> where <span class="math inline">\(A\)</span> is a normalizing constant.</p>
<p>The first thing to note from this expression is that the posterior distribution for the <span class="math inline">\(M\)</span> parameters for regression are themselves normally distributed.</p>
<p>The maximum likelihood estimate <span class="math inline">\(M_{r}\)</span> for the parameters <span class="math inline">\(M\)</span> occurs when <span class="math inline">\(P(M|Y,X)\)</span> is maximum, which we find by taking the derivatives. Using the matrix algebra developed in our linear regression chapter, we obtain the equation <span class="math display">\[
(X^{\intercal}Y-(X^{\intercal}X)M_r)/\sigma^2-M_r/\tau^{2}=0
\]</span> or <span id="eq-ridgeformula"><span class="math display">\[
(X^{\intercal}X+s)M_r=X^{\intercal}Y
\tag{3.4}\]</span></span> where <span class="math inline">\(s=\sigma^2/\tau^2\)</span>.</p>
<p>Therefore the ridge coefficients are given by the equation <span id="eq-ridgecoeffs"><span class="math display">\[
M_{r}=(X^{\intercal}X+s)^{-1}X^{\intercal}Y
\tag{3.5}\]</span></span></p>
<section id="practical-aspects-of-ridge-regression" class="level4" data-number="3.7.3.1">
<h4 data-number="3.7.3.1" class="anchored" data-anchor-id="practical-aspects-of-ridge-regression"><span class="header-section-number">3.7.3.1</span> Practical aspects of ridge regression</h4>
<p>Using ridge regression leads to a solution to the least squares problem in which the regression coefficients are biased towards being smaller. Beyond this, there are a number of implications of the technique which affect its use in practice.</p>
<p>First, we can put the Bayesian derivation of the ridge regression formulae in the background and focus our attention on <a href="#eq-ridgecoeffs">Equation&nbsp;<span>3.5</span></a>. We can treat the parameter <span class="math inline">\(s\)</span> (which must be non-negative) as “adjustable”.</p>
<p>One important consideration when using ridge regression is that <a href="#eq-ridgecoeffs">Equation&nbsp;<span>3.5</span></a> is not invariant if we scale <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> by a constant. This is different from “plain” regression where we consider the equation <span class="math inline">\(Y=XM\)</span>. In that case, rescaling <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> by the same factor leaves the coefficients <span class="math inline">\(M\)</span> alone. For this reason, ridge regression is typically used on centered, standardized coordinates. In other words, we replace each feature <span class="math inline">\(x_i\)</span> by <span class="math inline">\((x_i-\mu_i)/\sigma_i\)</span> where <span class="math inline">\(\mu_i\)</span> and <span class="math inline">\(\sigma_i\)</span> are the sample mean and standard deviation of the <span class="math inline">\(i^{th}\)</span> feature, and we replace our response variables <span class="math inline">\(y_i\)</span> similarly by <span class="math inline">\((y-\mu)/\sigma\)</span> where <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are the mean and standard deviation of the <span class="math inline">\(y\)</span>-values. Then we find <span class="math inline">\(M\)</span> using <a href="#eq-ridgecoeffs">Equation&nbsp;<span>3.5</span></a>, perhaps experimenting with different values of <span class="math inline">\(s\)</span>, using our centered and standardized variables.</p>
<p>To emphasize that we are using centered coordinates, we write <span class="math inline">\(X_{0}\)</span> for our data matrix instead of <span class="math inline">\(X\)</span>. Recall that the matrix <span class="math inline">\(X_0^{\intercal}X_0\)</span> that enters into <a href="#eq-ridgeformula">Equation&nbsp;<span>3.4</span></a> is <span class="math inline">\(ND_{0}\)</span> where <span class="math inline">\(D_{0}\)</span> is the covariance matrix. Therefore in ridge regression we have replaced <span class="math inline">\(ND_0\)</span> by <span class="math inline">\(ND_0+s\)</span>. Since <span class="math inline">\(D_0\)</span> is a real symmetric matrix, as we’ve seen in Chapter 2 it is diagonalizable so that <span class="math inline">\(AD_0A^{-1}\)</span> is diagonal for an orthogonal matrix <span class="math inline">\(A\)</span> and has eigenvalues <span class="math inline">\(\lambda_1\ge \ldots\ge \lambda_k\)</span> which are the variances of the data along the principal directions.</p>
<p>One effect of using ridge regression is that the eigenvalues of <span class="math inline">\(ND_{0}+s\)</span> are always at least <span class="math inline">\(s&gt;0\)</span>, so the use of ridge regression avoids the possibility that <span class="math inline">\(D_{0}\)</span> might not be invertible. In fact, a bit more is true. Numerical analysis tells us that when considering the problem of computing the inverse of a matrix, we should look at its <em>condition number</em>, which is the ratio <span class="math inline">\(\lambda_1/\lambda_k\)</span> of the largest to the smallest eigenvalue.</p>
<p>If the condition number of a matrix is large, then results from numerical analysis show that it is <em>almost singular</em> and its inverse becomes very sensitive to small changes in the entries of the matrix. However, the eigenvalues of <span class="math inline">\(ND_0+s\)</span> are <span class="math inline">\(N\lambda_{i}+s\)</span> and so the condition number becomes <span class="math inline">\((N\lambda_1+s)/(N\lambda_k+s)\)</span>. For larger values of <span class="math inline">\(\lambda\)</span>, this condition number shrinks, and so the inverse of the matrix <span class="math inline">\(ND_0+s\)</span> becomes better behaved than <span class="math inline">\(ND_{0}\)</span>. In this way, ridge regression helps to improve the numerical stability of the linear regression algorithm.</p>
<p>A second way to look at Ridge regression is to go back to the discussion of the singular value decomposition of the matrix <span class="math inline">\(X_{0}\)</span> in section <a href="02-pca.html#sec-svd"><span>Section&nbsp;2.4.2</span></a>. There we showed that the SVD of <span class="math inline">\(X_{0}\)</span> yields an expression <span class="math display">\[
X_{0}=U\tilde{\Lambda}P^{\intercal}
\]</span> where <span class="math inline">\(U\)</span> and <span class="math inline">\(P\)</span> are orthogonal matrices and <span class="math inline">\(\Lambda\)</span> is an <span class="math inline">\(N\times k\)</span> matrix whose upper block is diagonal with eigenvalues <span class="math inline">\(\sqrt{N\lambda_{i}}\)</span>. The rows of <span class="math inline">\(U\)</span> gave us an orthonormal basis that allowed us to write the predicted vector <span class="math inline">\(\hat{Y}\)</span> as a projection: <span class="math display">\[
\hat{Y}=\sum_{i=1}^{k} (u_j\cdot Y)u_{j}^{\intercal}.
\]</span></p>
<p>If we repeat this calculation, but using the ridge regression formula, we obtain <span class="math display">\[
\hat{Y}_{r}=X_{0}M_r = U\tilde{\Lambda}P^{\intercal}(P\tilde{\Lambda}^{\intercal}U^{\intercal}U\tilde{\Lambda}P^{\intercal}+s)^{-1}P\tilde{\Lambda}^{\intercal}U^{\intercal}Y.
\]</span> Since <span class="math inline">\(P\)</span> is orthogonal, <span class="math inline">\(P^{\intercal}=P^{-1}\)</span>, so <span class="math display">\[
P^{\intercal}(P\tilde{\Lambda}^2P^{\intercal}+s)^{-1}P=P^{-1}(P(\Lambda+s)P^{-1})P=(\Lambda+s)^{-1}
\]</span> and <span class="math inline">\(\Lambda+s\)</span> is a <span class="math inline">\(k\times k\)</span> diagonal matrix with entries <span class="math inline">\(N\lambda_{i}+s\)</span>.</p>
<p>Putting the pieces together we see that <span class="math display">\[
\hat{Y}_{r}=U\tilde{\Lambda}(\Lambda+s)^{-1}\tilde{\Lambda}U^{\intercal}Y.
\]</span></p>
<p>In the language of orthogonal projection, this means that <span class="math display">\[
\hat{Y}_{r} = \sum_{i=1}^{k} \frac{N\lambda_{i}}{N\lambda_{i}+s}(u_j\cdot Y)u_{j}^{\intercal}.
\]</span></p>
<p>In other words, the predicted value computed by ridge regression is obtained by projecting <span class="math inline">\(Y\)</span> into the space spanned by the feature vectors, but weighting the different principal components by <span class="math inline">\(N\lambda_{i}/(N\lambda_{i}+s)\)</span>. With this weighting, the principal components with smaller variances are weighted less than those with larger variances. For this reason, ridge regression is sometimes called a <em>shrinkage</em> method.</p>


</section>
</section>
</section>
<section id="bibliography" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body" role="doc-bibliography" style="display: none">
<div id="ref-Bertsekas" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline"><span class="smallcaps">Bertsekas</span>, D. P. and <span class="smallcaps">Tsitsiklis</span>, J. N. (2008). <em>Introduction to probability</em>. Athena Scientific.</div>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/02-pca.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Principal Component Analysis</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/04-naive-bayes.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">The Naive Bayes classification method</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>